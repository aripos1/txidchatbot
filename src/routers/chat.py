"""
Chat ë¼ìš°í„° (Refactored)
"""
from fastapi import APIRouter, Request
from fastapi.responses import HTMLResponse, JSONResponse, StreamingResponse
from fastapi.templating import Jinja2Templates

from chatbot import mongodb_client, get_chatbot_graph
from chatbot.models import get_default_chat_state
from langchain_core.messages import HumanMessage, AIMessage
import logging
import json
import uuid
import re

# ë¡œê±° ì„¤ì •
logger = logging.getLogger(__name__)

# ë¼ìš°í„° ì„¤ì •
router = APIRouter(prefix="", tags=["chat"])

# í…œí”Œë¦¿ì€ register_chat_routesì—ì„œ ì£¼ì…ë°›ìŒ
_templates = None

# --- ìƒìˆ˜ ë° í—¬í¼ í•¨ìˆ˜ ì •ì˜ ---

NODE_DISPLAY_NAMES = {
    "router": "ğŸ”€ ë¼ìš°íŒ… ì¤‘...",
    "simple_chat_specialist": "ğŸ’¬ ì‘ë‹µ ìƒì„± ì¤‘...",
    "faq_specialist": "ğŸ“š FAQ ê²€ìƒ‰ ì¤‘...",
    "transaction_specialist": "ğŸ” íŠ¸ëœì­ì…˜ ì¡°íšŒ ì¤‘...",
    "planner": "ğŸ“‹ ê²€ìƒ‰ ê³„íš ì¤‘...",
    "researcher": "ğŸ” ì›¹ ê²€ìƒ‰ ì¤‘...",
    "grader": "ğŸ“Š ê²°ê³¼ í‰ê°€ ì¤‘...",
    "writer": "âœï¸ ì‘ë‹µ ì‘ì„± ì¤‘...",
    "intent_clarifier": "ğŸ¤” ì˜ë„ í™•ì¸ ì¤‘...",
    "save_response": "ğŸ’¾ ì €ì¥ ì¤‘...",
    "coordinator": "ğŸ¤– ì¡°ì •ì ì‹¤í–‰ ì¤‘..."
}
# í—ˆìš©í•  ë…¸ë“œ ëª…ì‹œ (Whitelist)
# ì´ ë…¸ë“œë“¤ì˜ ì¶œë ¥ë§Œ ì‚¬ìš©ìì—ê²Œ ìŠ¤íŠ¸ë¦¬ë°ë©ë‹ˆë‹¤.
ALLOWED_STREAM_NODES = {
    "writer", 
    "simple_chat_specialist", 
    "faq_specialist", 
    "transaction_specialist", 
    "intent_clarifier"
}

RESPONSE_NODES = {
    "writer", "simple_chat_specialist", "faq_specialist", 
    "intent_clarifier", "transaction_specialist"
}

JSON_KEYWORDS = [
    '"search_queries"', '"research_plan"', '"priority"',
    '"score"', '"is_sufficient"', '"feedback"', '"missing_information"'
]

def clean_hidden_json(content: str) -> str:
    """
    LLM ì‘ë‹µ ì•ë¶€ë¶„ì— í¬í•¨ëœ JSON ë©”íƒ€ë°ì´í„°(ê²€ìƒ‰ ì¿¼ë¦¬ ë“±)ë¥¼ ì œê±°í•©ë‹ˆë‹¤.
    """
    cleaned_content = content.strip()
    
    # JSON êµ¬ì¡°ê°€ ì‹œì‘ë˜ê³  íŠ¹ì • í‚¤ì›Œë“œê°€ í¬í•¨ëœ ê²½ìš°
    if cleaned_content.startswith('{') and any(k in cleaned_content[:500] for k in JSON_KEYWORDS):
        brace_count = 0
        end_idx = 0
        for i, char in enumerate(cleaned_content):
            if char == '{':
                brace_count += 1
            elif char == '}':
                brace_count -= 1
                if brace_count == 0:
                    end_idx = i + 1
                    break
        
        if end_idx > 0:
            # JSON ë¶€ë¶„ ì œê±° ë° ì•ìª½ ê³µë°±/ê°œí–‰ ì œê±°
            return re.sub(r'^\s*\n\s*\n\s*', '', cleaned_content[end_idx:].lstrip()).strip()
            
    return cleaned_content

# extract_search_info_from_node_output í•¨ìˆ˜ëŠ” src.services.chat_serviceì—ì„œ import ê°€ëŠ¥
# í•„ìš”ì‹œ ì•„ë˜ ì£¼ì„ì„ í•´ì œí•˜ì—¬ ì‚¬ìš©:
# from src.services.chat_service import extract_search_info_from_node_output

# --- ë¼ìš°íŠ¸ ì •ì˜ ---

def register_chat_routes(app, templates: Jinja2Templates):
    """Chat ë¼ìš°íŠ¸ë¥¼ FastAPI ì•±ì— ë“±ë¡"""
    global _templates
    _templates = templates
    app.include_router(router)

@router.get("/chat", response_class=HTMLResponse)
async def chat_page(request: Request):
    """ì±—ë´‡ í˜ì´ì§€"""
    if _templates is None:
        from fastapi.templating import Jinja2Templates
        templates = Jinja2Templates(directory="templates")
    else:
        templates = _templates
    return templates.TemplateResponse("pages/chatbot.html", {"request": request})

@router.post("/api/chat/stream")
async def chat_stream(request: Request):
    """
    ìŠ¤íŠ¸ë¦¬ë° ì±„íŒ… ì—”ë“œí¬ì¸íŠ¸ (Server-Sent Events)
    LangGraph 1.0 astream_events ì‚¬ìš©
    """
    try:
        data = await request.json()
        message = data.get("message", "").strip()
        session_id = data.get("session_id", str(uuid.uuid4()))

        if not message:
            async def error_stream():
                yield f"data: {json.dumps({'type': 'error', 'content': 'ë©”ì‹œì§€ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.'})}\n\n"
            return StreamingResponse(error_stream(), media_type="text/event-stream")

        logger.info(f"[STREAM] ìŠ¤íŠ¸ë¦¬ë° ìš”ì²­ - Session: {session_id}, Message: {message[:50]}...")

        # 1. ê·¸ë˜í”„ ë° íˆìŠ¤í† ë¦¬ ë¡œë“œ
        graph = get_chatbot_graph()
        history_messages = []
        try:
            history = await mongodb_client.get_conversation_history(session_id, limit=10)
            for msg in history:
                if msg.get("role") == "user":
                    history_messages.append(HumanMessage(content=msg.get("content", "")))
                elif msg.get("role") == "assistant":
                    history_messages.append(AIMessage(content=msg.get("content", "")))
        except Exception as e:
            logger.warning(f"[STREAM] ëŒ€í™” ê¸°ë¡ ì¡°íšŒ ì‹¤íŒ¨ (ê³„ì† ì§„í–‰): {e}")

        # 2. ì´ˆê¸° ìƒíƒœ ì„¤ì •
        initial_state = get_default_chat_state(
            session_id=session_id,
            messages=history_messages + [HumanMessage(content=message)]
        )

        # 3. ìŠ¤íŠ¸ë¦¬ë° ìƒì„±ê¸° í•¨ìˆ˜
        async def generate_stream():
            final_response = ""
            current_node = None
            accumulated_content = {}
            coordinator_state_tracker = None
            # ì´ˆê¸° messages ê°œìˆ˜ ì €ì¥ (ìƒˆë¡œìš´ ë©”ì‹œì§€ë§Œ ì¶”ì¶œí•˜ê¸° ìœ„í•´)
            initial_messages_count = len(initial_state.get("messages", []))

            try:
                # User ë©”ì‹œì§€ ì €ì¥
                await mongodb_client.save_message(session_id, "user", message)
                yield f"data: {json.dumps({'type': 'start', 'session_id': session_id})}\n\n"

                # LangGraph ì´ë²¤íŠ¸ ë£¨í”„
                # coordinator ë‚´ë¶€ì˜ ì—ì´ì „íŠ¸ ì‹¤í–‰ì€ LangGraph ë…¸ë“œê°€ ì•„ë‹ˆë¯€ë¡œ
                # on_chain_endì—ì„œ coordinatorì˜ outputì„ í™•ì¸í•˜ì—¬ ì‹¤í–‰ëœ ë…¸ë“œë“¤ì„ ì¶”ë¡ í•´ì•¼ í•¨
                async for event in graph.astream_events(initial_state, version="v2"):
                    event_type = event.get("event", "")
                    event_name = event.get("name", "")
                    
                    # ëª¨ë“  ì´ë²¤íŠ¸ ë¡œê¹… (ë””ë²„ê¹…ìš© - ì²˜ìŒ 50ê°œë§Œ)
                    if event_type in ["on_chain_start", "on_chain_end"]:
                        logger.debug(f"ğŸ” [EVENT] {event_type}: {event_name}")

                    # --- [ì´ë²¤íŠ¸ 1] ë…¸ë“œ ì‹œì‘ (ìƒíƒœ ì—…ë°ì´íŠ¸) ---
                    if event_type == "on_chain_start":
                        parts = event_name.split("/")
                        
                        # ë…¸ë“œ ì´ë¦„ ì¶”ì¶œ: ê²½ë¡œì—ì„œ NODE_DISPLAY_NAMESì— ìˆëŠ” ì‹¤ì œ ë…¸ë“œ ì´ë¦„ ì°¾ê¸°
                        actual_node_name = None
                        
                        # 1ë‹¨ê³„: ëª¨ë“  ë¶€ë¶„ì„ í™•ì¸í•´ì„œ NODE_DISPLAY_NAMESì— ìˆëŠ” ë…¸ë“œ ì°¾ê¸°
                        for part in parts:
                            if part in NODE_DISPLAY_NAMES:
                                actual_node_name = part
                                break
                        
                        # 2ë‹¨ê³„: ì—†ìœ¼ë©´ ë§ˆì§€ë§‰ ë¶€ë¶„ ì‚¬ìš©
                        if not actual_node_name:
                            actual_node_name = parts[-1] if parts else event_name
                        
                        # ë‚´ë¶€ LangChain ì»´í¬ë„ŒíŠ¸ ì œì™¸ (LangGraph, RunnableSequence ë“±)
                        skip_nodes = ["LangGraph", "RunnableSequence", "ChatPromptTemplate", "ChatOpenAI", "StrOutputParser"]
                        
                        # [ë””ë²„ê¹…ìš© ë¡œê·¸] ì‹¤ì œ ì‹¤í–‰ë˜ëŠ” ë…¸ë“œ ì´ë¦„ì„ í™•ì¸í•˜ì„¸ìš”!
                        if actual_node_name not in skip_nodes:
                            logger.info(f"ğŸ‘‰ [NODE START] node_name: {actual_node_name} (path: {event_name})")
                            logger.info(f"   - NODE_DISPLAY_NAMESì— ìˆìŒ: {actual_node_name in NODE_DISPLAY_NAMES}")
                            if actual_node_name in NODE_DISPLAY_NAMES:
                                logger.info(f"   - í‘œì‹œ ì´ë¦„: {NODE_DISPLAY_NAMES[actual_node_name]}")
                            logger.info(f"   - ALLOWED_STREAM_NODESì— ìˆìŒ: {actual_node_name in ALLOWED_STREAM_NODES}")

                        # UI ìƒíƒœ ì—…ë°ì´íŠ¸: NODE_DISPLAY_NAMESì— ìˆëŠ” ë…¸ë“œë§Œ í‘œì‹œ
                        if actual_node_name in NODE_DISPLAY_NAMES and actual_node_name not in skip_nodes:
                            display_name = NODE_DISPLAY_NAMES[actual_node_name]
                            logger.info(f"ğŸ“¢ [UI UPDATE] ë…¸ë“œ ì‹œì‘ í‘œì‹œ: {actual_node_name} - {display_name}")
                            yield f"data: {json.dumps({'type': 'node', 'node': actual_node_name, 'display': display_name})}\n\n"
                            
                            # Coordinatorê°€ ì‹œì‘ë˜ë©´ ë‚´ë¶€ì—ì„œ ì‹¤í–‰ë  ë…¸ë“œë“¤ ì˜ˆìƒ í‘œì‹œ
                            # ì‹¤ì œë¡œëŠ” coordinatorê°€ ì‹¤í–‰ì„ ì™„ë£Œí•œ í›„ on_chain_endì—ì„œ ì •í™•í•œ ë…¸ë“œ ëª©ë¡ì„ í™•ì¸í•  ìˆ˜ ìˆì§€ë§Œ,
                            # ì‚¬ìš©ì ê²½í—˜ì„ ìœ„í•´ coordinatorê°€ ì‹œì‘ë  ë•Œ routerëŠ” ë¯¸ë¦¬ í‘œì‹œ
                            if actual_node_name == "coordinator":
                                # Coordinator ë‚´ë¶€ì—ì„œ routerëŠ” í•­ìƒ ì‹¤í–‰ë¨
                                if "router" in NODE_DISPLAY_NAMES:
                                    logger.info(f"ğŸ“¢ [COORDINATOR] router ë…¸ë“œ ë¯¸ë¦¬ í‘œì‹œ")
                                    yield f"data: {json.dumps({'type': 'node', 'node': 'router', 'display': NODE_DISPLAY_NAMES['router']}, ensure_ascii=False)}\n\n"
                            
                            # ìŠ¤íŠ¸ë¦¬ë° í—ˆìš© ë…¸ë“œ ì²´í¬
                            if actual_node_name in ALLOWED_STREAM_NODES:
                                current_node = actual_node_name
                                if actual_node_name not in accumulated_content:
                                    accumulated_content[actual_node_name] = ""

                    # --- [ì´ë²¤íŠ¸ 2] í† í° ìŠ¤íŠ¸ë¦¬ë° (LLM ì¶œë ¥) ---
                    elif event_type == "on_chat_model_stream":
                        chunk = event.get("data", {}).get("chunk")
                        
                        if chunk and hasattr(chunk, "content") and chunk.content:
                            token = chunk.content
                            
                            # event_nameì—ì„œ ì‹¤ì œ ë…¸ë“œ ì´ë¦„ ì¶”ì¶œ
                            # ì˜ˆ: "LangGraph/coordinator/writer/LangGraph" -> "writer"
                            stream_node_name = None
                            if "/" in event_name:
                                parts = event_name.split("/")
                                for part in parts:
                                    if part in ALLOWED_STREAM_NODES:
                                        stream_node_name = part
                                        break
                            else:
                                stream_node_name = event_name if event_name in ALLOWED_STREAM_NODES else None
                            
                            # í—ˆìš©ëœ ë…¸ë“œì˜ í† í°ë§Œ ì „ì†¡
                            if stream_node_name and stream_node_name in ALLOWED_STREAM_NODES:
                                current_node = stream_node_name
                                
                                # accumulated_contentì— í† í° ì¶”ê°€
                                if current_node not in accumulated_content:
                                    accumulated_content[current_node] = ""
                                accumulated_content[current_node] += token
                                
                                # í† í° ì „ì†¡ (JSON í•„í„°ë§ì€ ìµœì¢… ì‘ë‹µì—ì„œë§Œ ìˆ˜í–‰)
                                # logger.debug(f"[TOKEN] {stream_node_name}: {token[:50]}...")
                                yield f"data: {json.dumps({'type': 'token', 'content': token})}\n\n"

                    # --- [ì´ë²¤íŠ¸ 3] Coordinator ìƒíƒœ ë³€ê²½ (ê¸°ì¡´ ìœ ì§€) ---
                    elif event_type == "on_chain_stream":
                        chunk = event.get("data", {}).get("chunk", {})
                        if isinstance(chunk, dict) and ("coordinator" in event_name.lower()):
                            current_step = chunk.get("current_step")
                            display = chunk.get("current_step_display")
                            if current_step and display and coordinator_state_tracker != current_step:
                                coordinator_state_tracker = current_step
                                yield f"data: {json.dumps({'type': 'node', 'node': current_step, 'display': display})}\n\n"

                    # --- [ì´ë²¤íŠ¸ 4] ë…¸ë“œ ì¢…ë£Œ (ê¸°ì¡´ ìœ ì§€) ---
                    elif event_type == "on_chain_end":
                        # ë‚´ë¶€ LangChain ì»´í¬ë„ŒíŠ¸ ì œì™¸ (ê³µí†µ)
                        skip_nodes = ["LangGraph", "RunnableSequence", "ChatPromptTemplate", "ChatOpenAI", "StrOutputParser"]
                        
                        # event_nameì—ì„œ ì‹¤ì œ ë…¸ë“œ ì´ë¦„ ì¶”ì¶œ (ë” ì •í™•í•˜ê²Œ)
                        parts = event_name.split("/")
                        node_name = None
                        
                        # 1ë‹¨ê³„: NODE_DISPLAY_NAMESì—ì„œ ì°¾ê¸° (ìš°ì„ ìˆœìœ„ 1)
                        for part in parts:
                            if part in NODE_DISPLAY_NAMES and part not in skip_nodes:
                                node_name = part
                                break
                        
                        # 2ë‹¨ê³„: ALLOWED_STREAM_NODES ë˜ëŠ” RESPONSE_NODESì—ì„œ ì°¾ê¸°
                        if not node_name:
                            for part in parts:
                                if (part in ALLOWED_STREAM_NODES or part in RESPONSE_NODES) and part not in skip_nodes:
                                    node_name = part
                                    break
                        
                        # 3ë‹¨ê³„: ê·¸ë˜ë„ ì—†ìœ¼ë©´ ë§ˆì§€ë§‰ ë¶€ë¶„ ì‚¬ìš© (skip_nodes ì œì™¸)
                        if not node_name:
                            for part in reversed(parts):
                                if part not in skip_nodes:
                                    node_name = part
                                    break
                            if not node_name:
                                node_name = parts[-1] if parts else event_name
                        
                        output = event.get("data", {}).get("output", {})
                        
                        # ë””ë²„ê¹… ë¡œê·¸ (ëª¨ë“  ë…¸ë“œ ì¢…ë£Œ ì‹œ)
                        # skip_nodesê°€ ì•„ë‹Œ ê²½ìš°ì—ë§Œ ë¡œê¹…
                        if node_name not in skip_nodes:
                            logger.info(f"ğŸ‘‰ [NODE END] node_name: {node_name} (path: {event_name}), output_type: {type(output)}")
                            logger.info(f"   - NODE_DISPLAY_NAMESì— ìˆìŒ: {node_name in NODE_DISPLAY_NAMES}")
                            if node_name in NODE_DISPLAY_NAMES:
                                logger.info(f"   - í‘œì‹œ ì´ë¦„: {NODE_DISPLAY_NAMES[node_name]}")
                        
                        # ì¶œë ¥ êµ¬ì¡° í™•ì¸
                        if isinstance(output, dict):
                            logger.info(f"[CHAIN_END] output keys: {output.keys()}")
                            if "messages" in output:
                                msgs = output.get('messages', [])
                                logger.info(f"[CHAIN_END] messages count: {len(msgs)}")
                                if msgs:
                                    last_msg = msgs[-1]
                                    content_preview = last_msg.content[:100] if hasattr(last_msg, "content") else str(last_msg)[:100]
                                    logger.info(f"[CHAIN_END] last message preview: {content_preview}...")

                        # ë…¸ë“œë³„ ê²€ìƒ‰ ì •ë³´ ì¶”ì¶œ (ìƒê°í•˜ëŠ” ê³¼ì •ìš©)
                        search_info = {}
                        if isinstance(output, dict):
                            # FAQ ê²€ìƒ‰ ê²°ê³¼ (db_search_results)
                            db_results = output.get("db_search_results", [])
                            if db_results:
                                search_info["db_results"] = []
                                for r in db_results[:5]:  # ìµœëŒ€ 5ê°œë§Œ
                                    # URL ì¶”ì¶œ (ì—¬ëŸ¬ í•„ë“œì—ì„œ ì‹œë„)
                                    url = r.get("url") or r.get("source") or r.get("href") or ""
                                    # ë©”íƒ€ë°ì´í„°ì—ì„œ URL ì¶”ì¶œ
                                    metadata = r.get("metadata", {})
                                    if not url and isinstance(metadata, dict):
                                        url = metadata.get("url") or metadata.get("source") or metadata.get("href") or ""
                                    
                                    # ì œëª© ì¶”ì¶œ
                                    title = r.get("title") or r.get("text", "")[:50] or "FAQ ê²°ê³¼"
                                    
                                    search_info["db_results"].append({
                                        "title": title,
                                        "text": r.get("text", "")[:200],
                                        "url": url,
                                        "score": r.get("score", 0.0)
                                    })
                            
                            # ì›¹ ê²€ìƒ‰ ê²°ê³¼ (web_search_results)
                            web_results = output.get("web_search_results", [])
                            if web_results:
                                search_info["web_results"] = [
                                    {
                                        "title": r.get("title", "ì œëª© ì—†ìŒ"),
                                        "snippet": r.get("snippet", "")[:200],
                                        "url": r.get("url", "")
                                    }
                                    for r in web_results[:5]  # ìµœëŒ€ 5ê°œë§Œ
                                ]
                            
                            # ê²€ìƒ‰ ì¿¼ë¦¬ (search_queries)
                            search_queries = output.get("search_queries", [])
                            if search_queries:
                                search_info["queries"] = search_queries[:5]  # ìµœëŒ€ 5ê°œë§Œ
                            
                            # íŠ¸ëœì­ì…˜ ê²°ê³¼ (transaction_results)
                            tx_results = output.get("transaction_results")
                            if tx_results:
                                search_info["transaction_results"] = tx_results
                            
                            # ì—°êµ¬ ê³„íš (research_plan)
                            research_plan = output.get("research_plan", "")
                            if research_plan:
                                search_info["research_plan"] = research_plan[:200]
                            
                            # ê²€ìƒ‰ ì •ë³´ ì „ì†¡ (ìƒê°í•˜ëŠ” ê³¼ì •ìš©)
                            # search_infoê°€ ë¹„ì–´ìˆë”ë¼ë„ ë…¸ë“œ ì •ë³´ëŠ” ì „ì†¡ (í´ë¼ì´ì–¸íŠ¸ì—ì„œ ê¸°ë³¸ í‘œì‹œ ê°€ëŠ¥)
                            logger.info(f"ğŸ“Š [SEARCH_INFO] {node_name}: ì¿¼ë¦¬ {len(search_info.get('queries', []))}ê°œ, DB {len(search_info.get('db_results', []))}ê°œ, ì›¹ {len(search_info.get('web_results', []))}ê°œ")
                            yield f"data: {json.dumps({'type': 'node_search', 'node': node_name, 'search_info': search_info})}\n\n"

                        # ë…¸ë“œ ì¢…ë£Œ ì‹œ UI ì—…ë°ì´íŠ¸ (ì¤‘ìš”í•œ ë…¸ë“œë§Œ)
                        # NODE_DISPLAY_NAMESì— ìˆëŠ” ë…¸ë“œê°€ ì¢…ë£Œë˜ë©´ ìƒíƒœ ì—…ë°ì´íŠ¸ ì „ì†¡
                        if node_name in NODE_DISPLAY_NAMES and node_name not in skip_nodes:
                            logger.info(f"âœ… [NODE END] {node_name} ì™„ë£Œ")

                        # Coordinator ì „ë¬¸ê°€ ì„ íƒ ë¡œì§ ë° ë‚´ë¶€ ì—ì´ì „íŠ¸ ì¶”ì 
                        if node_name == "coordinator" and isinstance(output, dict):
                            specialist = output.get("specialist_used", "")
                            question_type = output.get("question_type")
                            
                            # Coordinator ë‚´ë¶€ì—ì„œ ì‹¤í–‰ëœ ì—ì´ì „íŠ¸ ì¶”ë¡ 
                            # specialist_used ë˜ëŠ” question_typeì„ ê¸°ë°˜ìœ¼ë¡œ ì‹¤ì œ ì‹¤í–‰ëœ ë…¸ë“œ ì¶”ë¡ 
                            executed_nodes = []
                            
                            # 1. Routerê°€ ì‹¤í–‰ë˜ì—ˆì„ ê°€ëŠ¥ì„± (coordinatorê°€ routerë¥¼ í˜¸ì¶œ)
                            if question_type or specialist:
                                executed_nodes.append("router")
                            
                            # 2. ì„ íƒëœ Specialist ì¶”ë¡ 
                            target_node = None
                            if specialist == "faq" or (question_type and str(question_type).endswith("FAQ")):
                                target_node = "faq_specialist"
                                executed_nodes.append("faq_specialist")
                            elif specialist == "web_search" or (question_type and "WEB_SEARCH" in str(question_type)):
                                target_node = "planner"
                                executed_nodes.extend(["planner", "researcher", "grader", "writer"])
                            elif specialist == "transaction" or (question_type and "TRANSACTION" in str(question_type)):
                                target_node = "transaction_specialist"
                                executed_nodes.append("transaction_specialist")
                            elif specialist == "simple_chat" or (question_type and "SIMPLE_CHAT" in str(question_type)):
                                target_node = "simple_chat_specialist"
                                executed_nodes.append("simple_chat_specialist")
                            
                            # ì‹¤í–‰ëœ ë…¸ë“œë“¤ì— ëŒ€í•´ ì´ë²¤íŠ¸ ì „ì†¡ (ì‹¤í–‰ ìˆœì„œëŒ€ë¡œ í‘œì‹œ)
                            # coordinator ë‚´ë¶€ì—ì„œ ì‹¤í–‰ëœ ë…¸ë“œë“¤ì´ LangGraph ë…¸ë“œê°€ ì•„ë‹ˆë¯€ë¡œ ì—¬ê¸°ì„œ ì „ì†¡
                            # router -> specialist ìˆœì„œë¡œ í‘œì‹œ
                            logger.info(f"ğŸ” [COORDINATOR] ì‹¤í–‰ëœ ë…¸ë“œ ì¶”ë¡ : {executed_nodes}")
                            for exec_node in executed_nodes:
                                if exec_node in NODE_DISPLAY_NAMES:
                                    display_name = NODE_DISPLAY_NAMES[exec_node]
                                    logger.info(f"ğŸ” [COORDINATOR] ë‚´ë¶€ ì—ì´ì „íŠ¸ ê°ì§€: {exec_node} - {display_name}")
                                    # ë…¸ë“œê°€ ì‹¤í–‰ë˜ì—ˆë‹¤ê³  ê°€ì •í•˜ê³  í‘œì‹œ
                                    yield f"data: {json.dumps({'type': 'node', 'node': exec_node, 'display': display_name}, ensure_ascii=False)}\n\n"
                                else:
                                    logger.warning(f"âš ï¸ [COORDINATOR] {exec_node}ê°€ NODE_DISPLAY_NAMESì— ì—†ìŒ - í‘œì‹œë˜ì§€ ì•ŠìŒ")
                            
                            # 3. Coordinatorì˜ stateì—ì„œ ê²€ìƒ‰ ì •ë³´ ì¶”ì¶œ (ë‚´ë¶€ ì—ì´ì „íŠ¸ë“¤ì´ ì‹¤í–‰ëœ ê²°ê³¼)
                            coordinator_search_info = {}
                            
                            # DB ê²€ìƒ‰ ê²°ê³¼ (FAQAgentê°€ ì‹¤í–‰ë˜ì—ˆì„ ê²½ìš°)
                            db_results = output.get("db_search_results", [])
                            if db_results:
                                coordinator_search_info["db_results"] = []
                                for r in db_results[:5]:
                                    url = r.get("url") or r.get("source") or r.get("href") or ""
                                    metadata = r.get("metadata", {})
                                    if not url and isinstance(metadata, dict):
                                        url = metadata.get("url") or metadata.get("source") or metadata.get("href") or ""
                                    title = r.get("title") or r.get("text", "")[:50] or "FAQ ê²°ê³¼"
                                    coordinator_search_info["db_results"].append({
                                        "title": title,
                                        "text": r.get("text", "")[:200],
                                        "url": url,
                                        "score": r.get("score", 0.0)
                                    })
                            
                            # ì›¹ ê²€ìƒ‰ ê²°ê³¼ (PlannerAgent â†’ ResearcherAgentê°€ ì‹¤í–‰ë˜ì—ˆì„ ê²½ìš°)
                            web_results = output.get("web_search_results", [])
                            if web_results:
                                coordinator_search_info["web_results"] = [
                                    {
                                        "title": r.get("title", "ì œëª© ì—†ìŒ"),
                                        "snippet": r.get("snippet", "")[:200],
                                        "url": r.get("url", "")
                                    }
                                    for r in web_results[:5]
                                ]
                            
                            # ê²€ìƒ‰ ì¿¼ë¦¬
                            search_queries = output.get("search_queries", [])
                            if search_queries:
                                coordinator_search_info["queries"] = search_queries[:5]
                            
                            # ì—°êµ¬ ê³„íš (research_plan)
                            research_plan = output.get("research_plan", "")
                            if research_plan:
                                coordinator_search_info["research_plan"] = research_plan[:200] if isinstance(research_plan, str) else str(research_plan)[:200]
                            
                            # Coordinatorì˜ ê²€ìƒ‰ ì •ë³´ ë¡œê¹… (ë””ë²„ê¹…ìš©)
                            logger.info(f"ğŸ“‹ [COORDINATOR] ê²€ìƒ‰ ì •ë³´ ì¶”ì¶œ ì™„ë£Œ:")
                            logger.info(f"   - ì¿¼ë¦¬: {len(coordinator_search_info.get('queries', []))}ê°œ")
                            logger.info(f"   - DB ê²°ê³¼: {len(coordinator_search_info.get('db_results', []))}ê°œ")
                            logger.info(f"   - ì›¹ ê²°ê³¼: {len(coordinator_search_info.get('web_results', []))}ê°œ")
                            logger.info(f"   - ì—°êµ¬ ê³„íš: {'ìˆìŒ' if coordinator_search_info.get('research_plan') else 'ì—†ìŒ'}")
                            logger.info(f"   - ì‹¤í–‰ëœ ë…¸ë“œ: {executed_nodes}")
                            
                            # Coordinator ë‚´ë¶€ ì—ì´ì „íŠ¸ë“¤ì˜ ê²€ìƒ‰ ì •ë³´ ì „ì†¡
                            # coordinator_search_infoì— ì •ë³´ê°€ ìˆìœ¼ë©´ ê° ë…¸ë“œì— ë§ê²Œ ì „ì†¡
                            # ê²€ìƒ‰ ì •ë³´ê°€ ìˆì–´ë„ ì—†ì–´ë„ ëª¨ë“  ë…¸ë“œì— ëŒ€í•´ node_search ì´ë²¤íŠ¸ ì „ì†¡ (ìƒê°í•˜ëŠ” ê³¼ì • í‘œì‹œìš©)
                            for exec_node in executed_nodes:
                                if exec_node not in ["router"]:  # routerëŠ” ê²€ìƒ‰ ì •ë³´ê°€ ì—†ìŒ
                                    node_search_info = {}
                                    
                                    # coordinator_search_infoì— ì •ë³´ê°€ ìˆìœ¼ë©´ ë…¸ë“œë³„ë¡œ ë§ëŠ” ì •ë³´ë§Œ í¬í•¨
                                    if coordinator_search_info:
                                        if exec_node == "faq_specialist":
                                            # FAQ ê´€ë ¨ ì •ë³´ë§Œ
                                            if "db_results" in coordinator_search_info:
                                                node_search_info["db_results"] = coordinator_search_info["db_results"]
                                            if "queries" in coordinator_search_info:
                                                node_search_info["queries"] = coordinator_search_info["queries"]
                                        elif exec_node in ["planner", "researcher"]:
                                            # ì›¹ ê²€ìƒ‰ ê´€ë ¨ ì •ë³´ë§Œ
                                            if "web_results" in coordinator_search_info:
                                                node_search_info["web_results"] = coordinator_search_info["web_results"]
                                            if "queries" in coordinator_search_info:
                                                node_search_info["queries"] = coordinator_search_info["queries"]
                                            if "research_plan" in coordinator_search_info:
                                                node_search_info["research_plan"] = coordinator_search_info["research_plan"]
                                        elif exec_node == "grader":
                                            # GraderëŠ” í‰ê°€ ì •ë³´ë§Œ
                                            if "queries" in coordinator_search_info:
                                                node_search_info["queries"] = coordinator_search_info["queries"]
                                        elif exec_node == "writer":
                                            # WriterëŠ” ëª¨ë“  ê²€ìƒ‰ ì •ë³´ í¬í•¨ (ìµœì¢… ì‘ë‹µ ìƒì„±ìš©)
                                            node_search_info = coordinator_search_info.copy()
                                    
                                    # node_search ì´ë²¤íŠ¸ ì „ì†¡ (ì •ë³´ê°€ ì—†ì–´ë„ ë‹¨ê³„ í‘œì‹œë¥¼ ìœ„í•´ í•­ìƒ ì „ì†¡)
                                    logger.info(f"ğŸ“Š [COORDINATOR] {exec_node} ê²€ìƒ‰ ì •ë³´ ì „ì†¡: ì¿¼ë¦¬ {len(node_search_info.get('queries', []))}ê°œ, DB {len(node_search_info.get('db_results', []))}ê°œ, ì›¹ {len(node_search_info.get('web_results', []))}ê°œ")
                                    yield f"data: {json.dumps({'type': 'node_search', 'node': exec_node, 'search_info': node_search_info}, ensure_ascii=False)}\n\n"
                            
                            # 4. Coordinatorì˜ outputì— messagesê°€ ìˆìœ¼ë©´ ì‘ë‹µ ì¶”ì¶œ
                            # ì£¼ì˜: coordinatorì˜ outputì—ëŠ” ì´ì „ ëŒ€í™”ì˜ ëª¨ë“  messagesê°€ í¬í•¨ë  ìˆ˜ ìˆìŒ
                            # ì‹¤ì œ ì‘ë‹µì€ ê° ì „ë¬¸ê°€ ë…¸ë“œ(simple_chat_specialist ë“±)ì—ì„œ ìƒì„±ë˜ë¯€ë¡œ,
                            # coordinatorì˜ messagesëŠ” ê±´ë„ˆë›°ê³  ì‹¤ì œ ì‘ë‹µ ë…¸ë“œì˜ outputì„ ì‚¬ìš©
                            logger.info("[CHAIN_END] coordinator - ì‹¤ì œ ì‘ë‹µì€ ì „ë¬¸ê°€ ë…¸ë“œì—ì„œ ì²˜ë¦¬í•˜ë¯€ë¡œ ê±´ë„ˆëœ€")

                        # ëª¨ë“  ë…¸ë“œì˜ outputì—ì„œ messages í™•ì¸ (ì‘ë‹µ ëˆ„ë½ ë°©ì§€)
                        # íŠ¹íˆ ainvokeë¥¼ ì‚¬ìš©í•˜ëŠ” ë…¸ë“œë“¤ì€ ìŠ¤íŠ¸ë¦¬ë°ë˜ì§€ ì•Šìœ¼ë¯€ë¡œ on_chain_endì—ì„œ ì²˜ë¦¬í•´ì•¼ í•¨
                        # coordinatorëŠ” ì´ë¯¸ ìœ„ì—ì„œ ì²˜ë¦¬í–ˆìœ¼ë¯€ë¡œ ê±´ë„ˆëœ€ (ì¤‘ë³µ ë°©ì§€)
                        if node_name != "coordinator" and isinstance(output, dict) and "messages" in output:
                            msgs = output.get("messages", [])
                            if msgs:
                                # ìƒˆë¡œìš´ ë©”ì‹œì§€ë§Œ ì¶”ì¶œ (ì´ì „ ëŒ€í™” ë©”ì‹œì§€ ì œì™¸)
                                # initial_messages_count ì´í›„ì˜ ë©”ì‹œì§€ë§Œ í™•ì¸
                                new_messages = msgs[initial_messages_count:] if len(msgs) > initial_messages_count else msgs[-1:] if msgs else []
                                
                                if not new_messages:
                                    # ìƒˆë¡œìš´ ë©”ì‹œì§€ê°€ ì—†ìœ¼ë©´ ë§ˆì§€ë§‰ ë©”ì‹œì§€ ì‚¬ìš© (fallback)
                                    logger.warning(f"[CHAIN_END] {node_name} - ìƒˆë¡œìš´ ë©”ì‹œì§€ ì—†ìŒ, ë§ˆì§€ë§‰ ë©”ì‹œì§€ ì‚¬ìš©")
                                    new_messages = [msgs[-1]]
                                
                                # ë§ˆì§€ë§‰ ìƒˆ ë©”ì‹œì§€ë§Œ ì‚¬ìš©
                                last_msg = new_messages[-1]
                                content = last_msg.content if hasattr(last_msg, "content") else str(last_msg)
                                logger.info(f"[CHAIN_END] {node_name} - ì „ì²´ messages: {len(msgs)}ê°œ, ì´ˆê¸°: {initial_messages_count}ê°œ, ìƒˆë¡œìš´: {len(new_messages)}ê°œ")
                                
                                # ì‘ë‹µ ë…¸ë“œì¸ ê²½ìš° ë¬´ì¡°ê±´ ì²˜ë¦¬
                                if node_name in ALLOWED_STREAM_NODES or node_name in RESPONSE_NODES:
                                    logger.info(f"[CHAIN_END] {node_name} ì²˜ë¦¬ ì‹œì‘ (ì‘ë‹µ ë…¸ë“œ)")
                                    logger.info(f"[CHAIN_END] {node_name} - messages: {len(msgs)}ê°œ, content ê¸¸ì´: {len(content) if content else 0}")
                                    
                                    if content and content.strip():
                                        existing_content = accumulated_content.get(node_name, "")
                                        logger.info(f"[CHAIN_END] {node_name} - existing_content ê¸¸ì´: {len(existing_content)}")
                                        
                                        # ê¸°ì¡´ì— ì „ì†¡ëœ ë‚´ìš©ê³¼ ë‹¤ë¥¸ ê²½ìš°, ë˜ëŠ” ì•„ì§ ì „ì†¡ë˜ì§€ ì•Šì€ ê²½ìš°
                                        if not existing_content or existing_content != content:
                                            # JSON í•„í„°ë§ ì ìš©
                                            cleaned_content = clean_hidden_json(content)
                                            logger.info(f"[CHAIN_END] {node_name} - í•„í„°ë§ í›„ ê¸¸ì´: {len(cleaned_content) if cleaned_content else 0}")
                                            if cleaned_content:
                                                logger.info(f"[RESPONSE] {node_name}: {cleaned_content[:100]}...")
                                                # í†µì§œ ì‘ë‹µì„ í† í°ìœ¼ë¡œ ì „ì†¡ (í•œ ë²ˆì—)
                                                yield f"data: {json.dumps({'type': 'token', 'content': cleaned_content})}\n\n"
                                                accumulated_content[node_name] = cleaned_content
                                                logger.info(f"[RESPONSE] {node_name} ì „ì†¡ ì™„ë£Œ - accumulated_contentì— ì¶”ê°€ë¨")
                                            else:
                                                logger.warning(f"[RESPONSE] {node_name}: í•„í„°ë§ í›„ ë‚´ìš©ì´ ë¹„ì–´ìˆìŒ")
                                        else:
                                            logger.debug(f"[RESPONSE] {node_name}: ì´ë¯¸ ì „ì†¡ëœ ë‚´ìš©ê³¼ ë™ì¼, ê±´ë„ˆëœ€")
                                    else:
                                        logger.warning(f"[RESPONSE] {node_name}: contentê°€ ì—†ìŒ")
                                
                                # ì‘ë‹µ ë…¸ë“œê°€ ì•„ë‹ˆë”ë¼ë„, accumulated_contentê°€ ë¹„ì–´ìˆê³  contentê°€ ìˆìœ¼ë©´ ì €ì¥
                                # (ë§ˆì§€ë§‰ ìˆ˜ë‹¨ìœ¼ë¡œ ì‘ë‹µ ì¶”ì¶œ)
                                elif not accumulated_content and content and content.strip():
                                    logger.warning(f"[CHAIN_END] {node_name}ëŠ” ì‘ë‹µ ë…¸ë“œê°€ ì•„ë‹ˆì§€ë§Œ messages ë°œê²¬ - ì‘ë‹µ ëˆ„ë½ ë°©ì§€ë¥¼ ìœ„í•´ ì €ì¥")
                                    cleaned_content = clean_hidden_json(content)
                                    if cleaned_content:
                                        logger.info(f"[RESPONSE] {node_name}ì—ì„œ ì‘ë‹µ ë°œê²¬ (í´ë°±): {cleaned_content[:100]}...")
                                        yield f"data: {json.dumps({'type': 'token', 'content': cleaned_content})}\n\n"
                                        accumulated_content[node_name] = cleaned_content
                        else:
                            # outputì— messagesê°€ ì—†ëŠ” ê²½ìš°
                            if node_name in ALLOWED_STREAM_NODES or node_name in RESPONSE_NODES:
                                logger.warning(f"[CHAIN_END] {node_name} - outputì— messagesê°€ ì—†ìŒ (output type: {type(output)})")
                            else:
                                logger.debug(f"[CHAIN_END] {node_name} - ALLOWED_STREAM_NODESì— ì—†ìŒ (í˜„ì¬ í—ˆìš© ë…¸ë“œ: {ALLOWED_STREAM_NODES})")

                # [Loop ì¢…ë£Œ í›„] ìµœì¢… ì •ë¦¬
                # accumulated_contentì— ì•„ë¬´ê²ƒë„ ì—†ìœ¼ë©´ on_chain_endì—ì„œ ì‘ë‹µì„ ë†“ì¹œ ê²ƒì¼ ìˆ˜ ìˆìŒ
                # ì´ ê²½ìš° ìµœì¢… ê·¸ë˜í”„ ì‹¤í–‰ ê²°ê³¼ì—ì„œ messagesë¥¼ ì¶”ì¶œí•´ì•¼ í•¨
                if accumulated_content:
                    if "writer" in accumulated_content:
                        raw_final = accumulated_content["writer"]
                    elif "coordinator" in accumulated_content:
                        raw_final = accumulated_content["coordinator"]
                    else:
                        raw_final = list(accumulated_content.values())[-1]
                    
                    # ìµœì¢… ì €ì¥ ì‹œì—ë§Œ JSON íƒœê·¸ ì²­ì†Œ
                    final_response = clean_hidden_json(raw_final)
                    logger.info(f"[FINAL] ìµœì¢… ì‘ë‹µ ê¸¸ì´: {len(final_response)}ì (from accumulated_content)")
                else:
                    # accumulated_contentê°€ ë¹„ì–´ìˆìœ¼ë©´ ê·¸ë˜í”„ì˜ ìµœì¢… ìƒíƒœì—ì„œ ì§ì ‘ ì¶”ì¶œ ì‹œë„
                    logger.warning("[FINAL] accumulated_contentê°€ ë¹„ì–´ìˆìŒ - ê·¸ë˜í”„ ìµœì¢… ìƒíƒœì—ì„œ ì‘ë‹µ ì¶”ì¶œ ì‹œë„")
                    
                    # ê·¸ë˜í”„ë¥¼ ë‹¤ì‹œ ì‹¤í–‰í•´ì„œ ìµœì¢… ìƒíƒœ í™•ì¸ (ë¹„íš¨ìœ¨ì ì´ì§€ë§Œ ì‘ë‹µ ëˆ„ë½ ë°©ì§€)
                    # ëŒ€ì‹  ë§ˆì§€ë§‰ ì´ë²¤íŠ¸ì˜ outputì—ì„œ messages í™•ì¸
                    final_response = ""
                    
                    # ì£¼ì˜: ì´ ë¶€ë¶„ì€ ì´ë¯¸ ì™„ë£Œëœ ì´ë²¤íŠ¸ ìŠ¤íŠ¸ë¦¼ì´ë¯€ë¡œ,
                    # ì‹¤ì œë¡œëŠ” í´ë¼ì´ì–¸íŠ¸ ì¸¡ì—ì„œ final_responseë¥¼ ì‚¬ìš©í•´ì•¼ í•¨
                    logger.warning("[FINAL] accumulated_contentê°€ ë¹„ì–´ìˆìŒ - í´ë¼ì´ì–¸íŠ¸ì—ì„œ final_response í™•ì¸ í•„ìš”")
                
                # ì™„ë£Œ ì´ë²¤íŠ¸ ì „ì†¡
                logger.info(f"[DONE] ì™„ë£Œ ì´ë²¤íŠ¸ ì „ì†¡ ì‹œì‘ - final_response ê¸¸ì´: {len(final_response)}ì")
                logger.info(f"[DONE] accumulated_content: {list(accumulated_content.keys())}")
                done_event = f"data: {json.dumps({'type': 'done', 'final_response': final_response}, ensure_ascii=False)}\n\n"
                logger.info(f"[DONE] done ì´ë²¤íŠ¸ ë¬¸ìì—´: {done_event[:200]}...")
                yield done_event
                logger.info("[DONE] ì™„ë£Œ ì´ë²¤íŠ¸ ì „ì†¡ ì™„ë£Œ - yield ì‹¤í–‰ë¨")
                
                # ì¶”ê°€ flush (í™•ì‹¤íˆ ì „ì†¡ë˜ë„ë¡)
                import sys
                if hasattr(sys.stdout, 'flush'):
                    sys.stdout.flush()

            except Exception as e:
                logger.error(f"[STREAM] ìŠ¤íŠ¸ë¦¬ë° ì¤‘ ì˜¤ë¥˜: {e}", exc_info=True)
                yield f"data: {json.dumps({'type': 'error', 'content': f'ì˜¤ë¥˜ ë°œìƒ: {str(e)}'})}\n\n"

        return StreamingResponse(
            generate_stream(),
            media_type="text/event-stream",
            headers={
                "Cache-Control": "no-cache",
                "Connection": "keep-alive",
                "X-Accel-Buffering": "no",
                "Access-Control-Allow-Origin": "*",
            }
        )

    except Exception as e:
        logger.error(f"[STREAM] ìš”ì²­ ì²˜ë¦¬ ì‹¤íŒ¨: {e}", exc_info=True)
        return JSONResponse(status_code=500, content={"error": str(e)})


@router.get("/api/chat/history/{session_id}")
async def get_chat_history(session_id: str):
    """ëŒ€í™” ê¸°ë¡ ì¡°íšŒ"""
    try:
        history = await mongodb_client.get_conversation_history(session_id, limit=50)
        serialized_history = []
        for msg in history:
            serialized_msg = dict(msg)
            # ObjectId ë° datetime ë¬¸ìì—´ ë³€í™˜
            if "_id" in serialized_msg:
                serialized_msg["_id"] = str(serialized_msg["_id"])
            if "created_at" in serialized_msg and hasattr(serialized_msg["created_at"], "isoformat"):
                serialized_msg["created_at"] = serialized_msg["created_at"].isoformat()
            serialized_history.append(serialized_msg)
        return JSONResponse(content={"history": serialized_history})
    except Exception as e:
        logger.error(f"ëŒ€í™” ê¸°ë¡ ì¡°íšŒ ì‹¤íŒ¨: {e}", exc_info=True)
        return JSONResponse(content={"error": str(e)}, status_code=500)

@router.delete("/api/chat/history/{session_id}")
async def clear_chat_history(session_id: str):
    """ëŒ€í™” ê¸°ë¡ ì‚­ì œ"""
    try:
        success = await mongodb_client.clear_conversation(session_id)
        return JSONResponse(content={"success": success})
    except Exception as e:
        return JSONResponse(content={"error": str(e)}, status_code=500)